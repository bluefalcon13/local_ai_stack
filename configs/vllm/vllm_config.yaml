# Model Configuration
model: "mistralai/Devstral-Small-2-24B-Instruct-2512"
dtype: "float16"
quantization: none

# Performance Tuning
gpu_memory_utilization: 0.60
max_model_len: 32768
enforce_eager: true
attention_backend: "TRITON_ATTN"

# Serving
max_num_batched_tokens: 4096
max_num_seqs: 4
host: "0.0.0.0"
port: 8000
chat_template_content_format: "openai"