services:
  # --- THE GATEWAY ---
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: cloudflared
    restart: unless-stopped
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    command: tunnel --no-autoupdate run
    networks:
      - ai-frontend

  # --- The GATEKEEPER ---
  caddy:
    image: caddy:latest
    container_name: caddy
    environment:
      - BASE_DOMAIN=${BASE_DOMAIN}
      - TLS_CLIENT_CERT_NAME=${TLS_CLIENT_CERT_NAME}
      - TLS_CLIENT_KEY_NAME=${TLS_CLIENT_KEY_NAME}
      - CLOUDFLARE_AUTH_ORIGIN_PULL_CERT_NAME=${CLOUDFLARE_AUTH_ORIGIN_PULL_CERT_NAME}
    volumes:
      - ${CONFIG_ROOT}/caddy/Caddyfile:/etc/caddy/Caddyfile:ro
      - ${CONFIG_ROOT}/caddy/cloudflare_certs:/data:ro
      - /home/${SERVICE_USER}/caddy_config:/config2
    networks:
      - ai-frontend

  # --- THE AGENTIC BRAIN ---
  langgraph:
    image: langchain/langgraph-api:latest
    container_name: langgraph-api
    restart: unless-stopped
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      - OLLAMA_BASE_URL=http://ollama-main:11434
      - DATABASE_URI=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@langgraph-db:5432/${POSTGRES_DB}
    volumes:
      - ${CONFIG_ROOT}/langgraph/agents:/app/agents
    networks:
      - ai-frontend
      - ai-isolated 
    depends_on:
      - langgraph-db

  langgraph-db:
    image: postgres:16
    container_name: langgraph-db
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    volumes:
      - /home/${SERVICE_USER}/langgraph_db:/var/lib/postgresql/data
    networks:
      - ai-isolated

  # --- THE INTERFACE ---
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      - 'WEBUI_SECRET_KEY=${WEBUI_SECRET}'
      - 'OLLAMA_BASE_URLS=http://ollama-main:11434;http://tpu-worker:8080'
      - 'OPENAI_API_BASE_URL=http://langgraph:8000/v1' 
      - 'SEARXNG_QUERY_URL=http://searxng:8080/search?q=<query>'
    volumes:
      - /home/${SERVICE_USER}/webui_data:/app/backend/data
    networks:
      - ai-frontend
      - ai-search
      - ai-isolated

  # --- THE MUSCLE (STRIX HALO POWER) ---
  ollama-main:
    image: ollama/ollama:latest
    container_name: ollama-main
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      - HSA_OVERRIDE_GFX_VERSION=11.5.1
    devices:
      - /dev/kfd:/dev/kfd
      - /dev/dri:/dev/dri
    volumes:
      - /home/${SERVICE_USER}/ollama_main:/root/.ollama
    networks:
      - ai-isolated 

  tpu-worker:
    image: localai/localai:latest-tpu
    container_name: tpu-worker
    user: "${SERVICE_UID}:${SERVICE_UID}"
    devices:
      - /dev/apex_0:/dev/apex_0
    networks:
      - ai-isolated

  # --- SEARCH & METRICS ---
  searxng:
    image: docker.io/searxng/searxng:latest
    container_name: searxng
    user: "${SERVICE_UID}:${SERVICE_UID}"
    environment:
      - SEARXNG_SECRET=${SEARXNG_SECRET}
    volumes:
      - ${CONFIG_ROOT}/searxng:/etc/searxng:ro
    networks:
      - ai-search

  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: phoenix
    user: "${SERVICE_UID}:${SERVICE_UID}"
    networks:
      - ai-frontend

networks:
  ai-frontend:
    driver: bridge
  ai-search:
    driver: bridge
  ai-isolated:
    driver: bridge
    internal: true